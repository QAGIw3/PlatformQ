env {
  execution.parallelism = 10
  job.mode = "STREAMING"
  checkpoint.interval = 60000
  execution.checkpoint.data-uri = "s3://platformq-checkpoints/seatunnel/blockchain/"
}

source {
  # Ethereum blockchain events
  Ethereum {
    rpc_endpoint = "https://eth-mainnet.g.alchemy.com/v2/${ALCHEMY_API_KEY}"
    start_block = "latest"
    contract_addresses = [
      "${PLATFORM_ASSET_CONTRACT}",
      "${USAGE_LICENSE_CONTRACT}",
      "${ROYALTY_DISTRIBUTOR_CONTRACT}",
      "${AUCTION_HOUSE_CONTRACT}",
      "${NFT_LENDING_CONTRACT}",
      "${YIELD_FARMING_CONTRACT}",
      "${MARKETPLACE_DAO_CONTRACT}"
    ]
    events = [
      "Transfer",
      "Approval",
      "NFTMinted",
      "LicensePurchased",
      "RoyaltyDistributed",
      "AuctionCreated",
      "BidPlaced",
      "AuctionEnded",
      "LoanCreated",
      "LoanRepaid",
      "NFTStaked",
      "RewardsClaimed",
      "ProposalCreated",
      "VoteCast"
    ]
    poll_interval_ms = 5000
    max_block_range = 100
    result_table_name = "ethereum_events"
  }
  
  # Polygon blockchain events
  Polygon {
    rpc_endpoint = "https://polygon-mainnet.g.alchemy.com/v2/${ALCHEMY_POLYGON_KEY}"
    start_block = "latest"
    contract_addresses = [
      "${POLYGON_PLATFORM_ASSET_CONTRACT}",
      "${POLYGON_USAGE_LICENSE_CONTRACT}",
      "${POLYGON_ROYALTY_DISTRIBUTOR_CONTRACT}"
    ]
    events = ["Transfer", "NFTMinted", "LicensePurchased", "RoyaltyDistributed"]
    poll_interval_ms = 3000
    max_block_range = 200
    result_table_name = "polygon_events"
  }
  
  # Solana blockchain events
  Solana {
    rpc_endpoint = "https://api.mainnet-beta.solana.com"
    programs = [
      "${SOLANA_MARKETPLACE_PROGRAM}",
      "${SOLANA_NFT_PROGRAM}"
    ]
    commitment = "confirmed"
    poll_interval_ms = 1000
    result_table_name = "solana_events"
  }
  
  # IPFS metadata
  IPFS {
    gateway_urls = [
      "https://ipfs.io/ipfs/",
      "https://gateway.pinata.cloud/ipfs/",
      "https://cloudflare-ipfs.com/ipfs/"
    ]
    retry_times = 3
    timeout_ms = 10000
    result_table_name = "ipfs_metadata"
  }
  
  # Chainlink price feeds
  Chainlink {
    rpc_endpoint = "https://eth-mainnet.g.alchemy.com/v2/${ALCHEMY_API_KEY}"
    price_feeds = [
      {
        name = "ETH/USD"
        address = "0x5f4eC3Df9cbd43714FE2740f5E3616155c5b8419"
      },
      {
        name = "MATIC/USD"
        address = "0x7bAC85A8a13A4BcD8abb3eB7d6b4d632c5a57676"
      },
      {
        name = "SOL/USD"
        address = "0x4ffC43a60e009B551865A93d232E33Fce9f01507"
      }
    ]
    poll_interval_ms = 60000
    result_table_name = "price_feeds"
  }
}

transform {
  # Parse and enrich blockchain events
  sql {
    sql = """
      SELECT 
        event_type,
        block_number,
        transaction_hash,
        log_index,
        contract_address,
        from_address,
        to_address,
        token_id,
        value,
        data,
        timestamp,
        'ethereum' as chain,
        CASE 
          WHEN event_type = 'NFTMinted' THEN 'mint'
          WHEN event_type = 'LicensePurchased' THEN 'license'
          WHEN event_type = 'RoyaltyDistributed' THEN 'royalty'
          WHEN event_type IN ('AuctionCreated', 'BidPlaced', 'AuctionEnded') THEN 'auction'
          WHEN event_type IN ('LoanCreated', 'LoanRepaid') THEN 'lending'
          WHEN event_type IN ('NFTStaked', 'RewardsClaimed') THEN 'staking'
          ELSE 'other'
        END as operation_category,
        CAST(value AS DECIMAL(38, 18)) / 1e18 as value_eth
      FROM ethereum_events
    """
    result_table_name = "enriched_ethereum_events"
  }
  
  # Calculate transaction volumes
  sql {
    sql = """
      SELECT 
        chain,
        operation_category,
        DATE_TRUNC('hour', timestamp) as hour,
        COUNT(*) as transaction_count,
        SUM(value_eth) as volume_eth,
        AVG(value_eth) as avg_value_eth,
        MAX(value_eth) as max_value_eth
      FROM (
        SELECT * FROM enriched_ethereum_events
        UNION ALL
        SELECT *, 'polygon' as chain, value / 1e18 as value_eth FROM polygon_events
        UNION ALL
        SELECT *, 'solana' as chain, value / 1e9 as value_eth FROM solana_events
      )
      GROUP BY chain, operation_category, hour
    """
    result_table_name = "hourly_volumes"
  }
  
  # Extract NFT metadata
  sql {
    sql = """
      SELECT 
        e.token_id,
        e.contract_address,
        e.chain,
        m.name,
        m.description,
        m.image,
        m.attributes,
        m.external_url,
        e.timestamp as mint_timestamp,
        e.from_address as creator
      FROM enriched_ethereum_events e
      JOIN ipfs_metadata m ON e.data = m.ipfs_hash
      WHERE e.event_type = 'NFTMinted'
    """
    result_table_name = "nft_metadata"
  }
  
  # Track user activity
  sql {
    sql = """
      SELECT 
        user_address,
        chain,
        COUNT(DISTINCT CASE WHEN operation_category = 'mint' THEN token_id END) as nfts_minted,
        COUNT(DISTINCT CASE WHEN operation_category = 'license' THEN token_id END) as licenses_purchased,
        SUM(CASE WHEN operation_category = 'royalty' THEN value_eth ELSE 0 END) as royalties_earned,
        COUNT(DISTINCT transaction_hash) as total_transactions,
        MIN(timestamp) as first_activity,
        MAX(timestamp) as last_activity
      FROM (
        SELECT from_address as user_address, * FROM enriched_ethereum_events
        UNION ALL
        SELECT to_address as user_address, * FROM enriched_ethereum_events
      )
      WHERE user_address != '0x0000000000000000000000000000000000000000'
      GROUP BY user_address, chain
    """
    result_table_name = "user_activity"
  }
  
  # Price conversion
  sql {
    sql = """
      SELECT 
        e.*,
        e.value_eth * p.price as value_usd,
        p.price as eth_price_usd
      FROM enriched_ethereum_events e
      CROSS JOIN LATERAL (
        SELECT price 
        FROM price_feeds 
        WHERE name = 'ETH/USD' 
        AND timestamp <= e.timestamp 
        ORDER BY timestamp DESC 
        LIMIT 1
      ) p
    """
    result_table_name = "events_with_usd"
  }
}

sink {
  # Write to data lake (MinIO)
  S3File {
    path = "s3://data-lake/blockchain/events/"
    bucket = "data-lake"
    file_format = "parquet"
    partition_by = ["chain", "date=${timestamp:yyyy-MM-dd}"]
    source_table_name = "events_with_usd"
    hadoop_s3_properties {
      "fs.s3a.endpoint" = "http://minio:9000"
      "fs.s3a.access.key" = "${MINIO_ACCESS_KEY}"
      "fs.s3a.secret.key" = "${MINIO_SECRET_KEY}"
      "fs.s3a.path.style.access" = "true"
    }
  }
  
  # Write volumes to Cassandra for time-series
  Cassandra {
    host = "cassandra:9042"
    keyspace = "marketplace"
    table = "hourly_volumes"
    source_table_name = "hourly_volumes"
    username = "${CASSANDRA_USER}"
    password = "${CASSANDRA_PASSWORD}"
    consistency_level = "LOCAL_QUORUM"
  }
  
  # Write NFT metadata to Elasticsearch
  Elasticsearch {
    hosts = ["http://elasticsearch:9200"]
    index = "nft_metadata"
    source_table_name = "nft_metadata"
    index_type = "_doc"
    bulk_size = 1000
    max_retry_times = 3
  }
  
  # Write user activity to JanusGraph
  JanusGraph {
    backend = "cql"
    hostname = "cassandra:9042"
    graph_name = "marketplace_graph"
    source_table_name = "user_activity"
    vertex_label = "user"
    vertex_id_field = "user_address"
    properties = ["chain", "nfts_minted", "licenses_purchased", "royalties_earned"]
  }
  
  # Stream to Pulsar for real-time processing
  Pulsar {
    service_url = "pulsar://pulsar:6650"
    topic = "blockchain-events"
    source_table_name = "events_with_usd"
    format = "json"
    producer_config {
      sendTimeoutMs = 30000
      blockIfQueueFull = true
    }
  }
  
  # Cache recent events in Ignite
  Ignite {
    hosts = "ignite:10800"
    cache_name = "recent_blockchain_events"
    source_table_name = "events_with_usd"
    key_field = "transaction_hash"
    write_mode = "overwrite"
    expiry_time = 3600  # 1 hour TTL
  }
}

# Error handling
error {
  # Dead letter queue for failed records
  S3File {
    path = "s3://data-lake/blockchain/errors/"
    bucket = "data-lake"
    file_format = "json"
    partition_by = ["date=${current_date:yyyy-MM-dd}", "hour=${current_date:HH}"]
    hadoop_s3_properties {
      "fs.s3a.endpoint" = "http://minio:9000"
      "fs.s3a.access.key" = "${MINIO_ACCESS_KEY}"
      "fs.s3a.secret.key" = "${MINIO_SECRET_KEY}"
      "fs.s3a.path.style.access" = "true"
    }
  }
} 